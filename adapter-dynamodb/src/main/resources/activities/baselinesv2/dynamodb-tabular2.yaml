min_version: "5.17.1"

description: |
  Run a read/write workload against DynamoDB with varying field sizes and query patterns

scenarios:
  schema: run driver=dynamodb tags=block:"schema.*" region=us-east-1
  rampup: run driver=dynamodb tags=block:rampup region=us-east-1
  read: run driver=dynamodb tags=block:read region=us-east-1
  main: run driver=dynamodb tags=block:"main.*" region=us-east-1
  read01: run driver=dynamodb tags='name:.*main-read-01' region=us-east-1
  delete:
    table: run driver=dynamodb tags==block:delete threads==1 cycles==UNDEF

bindings:
  # for ramp-up and verify phases
  part_layout: Div(<<partsize:1000000>>); ToString() -> String
  clust_layout: Mod(<<partsize:1000000>>); ToString() -> String
  # todo: update these definitions to use the simpler 10,0.1, 20, 0.2, ...
  data0: Add(10); HashedFileExtractToString('data/lorem_ipsum_full.txt',9,11); EscapeJSON();
  data1: Add(20); HashedFileExtractToString('data/lorem_ipsum_full.txt',18,22); EscapeJSON();
  data2: Add(30); HashedFileExtractToString('data/lorem_ipsum_full.txt',27,33); EscapeJSON();
  data3: Add(40); HashedFileExtractToString('data/lorem_ipsum_full.txt',45,55); EscapeJSON();
  data4: Add(50); HashedFileExtractToString('data/lorem_ipsum_full.txt',72,88); EscapeJSON();
  data5: Add(60); HashedFileExtractToString('data/lorem_ipsum_full.txt',117,143); EscapeJSON();
  data6: Add(70); HashedFileExtractToString('data/lorem_ipsum_full.txt',189,231); EscapeJSON();
  data7: Add(80); HashedFileExtractToString('data/lorem_ipsum_full.txt',306,374); EscapeJSON();

  # for main phase
  # for write
  part_write: Hash(); Uniform(0,<<partcount:100>>)->int; ToString() -> String
  clust_write: Hash(); Add(1); Uniform(0,<<partsize:1000000>>)->int; ToString() -> String
  data_write: Hash(); HashedFileExtractToString('data/lorem_ipsum_full.txt',50,150) -> String

  # for read
  limit: Uniform(1,10) -> int
  part_read: Uniform(0,<<partcount:100>>)->int; ToString() -> String
  clust_read: Add(1); Uniform(0,<<partsize:1000000>>)->int; ToString() -> String

params:
  instrument: true

blocks:
  schema:
    ops:
      create-table:
        CreateTable: TEMPLATE(table,tabular)
        Keys:
          part: HASH
          clust: RANGE
        Attributes:
          part: S
          clust: S
        BillingMode: PROVISIONED
        ReadCapacityUnits: "TEMPLATE(rcus,40000)"
        WriteCapacityUnits: "TEMPLATE(wcus,40000)"
  #          BillingMode: PAY_PER_REQUEST
  rampup:
    ops:
      put-items:
        PutItem: TEMPLATE(table,tabular)
        json: |
          {
           "part": "{part_layout}",
           "clust": "{clust_layout}",
           "data0": "{data0}",
           "data1": "{data1}",
           "data2": "{data2}",
           "data3": "{data3}",
           "data4": "{data4}",
           "data5": "{data5}",
           "data6": "{data6}",
           "data7": "{data7}"
          }
  read:
    params:
      ratio: 1
    ops:
      read-all:
        GetItem: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
  main:
    ops:
      write-all:
        params:
          ratio: 8
        PutItem: TEMPLATE(table,tabular)
        json: |
          {
           "part": "{part_layout}",
           "clust": "{clust_layout}",
           "data0": "{data0}",
           "data1": "{data1}",
           "data2": "{data2}",
           "data3": "{data3}",
           "data4": "{data4}",
           "data5": "{data5}",
           "data6": "{data6}",
           "data7": "{data7}"
          }
      main-read-all:
        Query: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
        ConsistentRead: true
        Limit: "{limit}"
        # no attributes means "all" implicitly

      main-read-01:
        Query: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
        ConsistentRead: true
        projection: data0, data1
        Limit: "{limit}"

      main-read-0246:
        Query: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
        ConsistentRead: true
        projection: data0, data2, data4, data6
        Limit: "{limit}"

      main-read-1357:
        Query: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
        ConsistentRead: true
        projection: data1, data3, data5, data7
        Limit: "{limit}"

      main-read-0123:
        Query: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
        ConsistentRead: true
        projection: data0, data1, data2, data3
        Limit: "{limit}"

      main-read-4567:
        Query: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
        ConsistentRead: true
        projection: data4, data5, data6, data7
        Limit: "{limit}"

      main-read-67:
        Query: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
        ConsistentRead: true
        projection: data6, data7
        Limit: "{limit}"

      main-read-01234567:
        Query: TEMPLATE(table,tabular)
        key:
          part: "{part_read}"
          clust: "{clust_read}"
        ConsistentRead: true
        projection: data0, data1, data2, data3, data4, data5, data6, data7
        Limit: "{limit}"

  delete:
    ops:
      delete-table:
        DeleteTable: TEMPLATE(table,tabular)
