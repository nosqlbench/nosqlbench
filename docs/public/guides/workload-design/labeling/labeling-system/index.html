<!doctype html><html lang=en><head><script integrity=sha384-pb++s6uBRKaQv+iAXpgA/H3IlpLZdO14tTwuCI7uXmz4aaZdByoCcM+6BhynMq/1 src=https://docs.nosqlbench.io/js/theme.min.js></script><link href="https://docs.nosqlbench.io/abridge.css?h=17d1d14ae374495df55a" rel=stylesheet><meta charset=utf-8><meta content="ie=edge" http-equiv=x-ua-compatible><meta content="width=device-width,initial-scale=1" name=viewport><meta content=https://docs.nosqlbench.io name=base><meta content=True name=HandheldFriendly><meta content=yes name=mobile-web-app-capable><meta content=yes name=apple-mobile-web-app-capable><meta content=default name=apple-mobile-web-app-status-bar-style><link href=https://docs.nosqlbench.io/favicon.svg rel=icon type=image/svg+xml><link title="NoSQLBench Documentation Atom Feed" href=https://docs.nosqlbench.io/atom.xml rel=alternate type=application/atom+xml><meta content="index, follow" name=robots><meta content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1" name=googlebot><meta content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1" name=bingbot><title>Understanding Labels | NoSQLBench Documentation</title><meta content="NoSQLBench Team" name=author><meta content="NoSQLBench Documentation" name=copyright><meta content="How the NoSQLBench labeling system organizes test results" name=description><link href=https://docs.nosqlbench.io/guides/workload-design/labeling/labeling-system/ rel=canonical><meta content=https://docs.nosqlbench.io/guides/workload-design/labeling/labeling-system/ property=og:url><meta content=https://docs.nosqlbench.io/guides/workload-design/labeling/labeling-system/ name=twitter:url><meta content="How the NoSQLBench labeling system organizes test results" property=og:description><meta content="How the NoSQLBench labeling system organizes test results" name=twitter:description><meta content="Understanding Labels | NoSQLBench Documentation" property=og:title><meta content="Understanding Labels | NoSQLBench Documentation" name=twitter:title><meta content=summary name=twitter:card><meta content="NoSQLBench Documentation" property=og:site_name><meta content=en_US property=og:locale><meta content=website property=og:type><meta property=og:updated_time><script src="https://docs.nosqlbench.io/js/theme_button.js?h=12a31e87fcbe7a55e953" defer integrity=sha384-UBxLGgFVZtEgNzOU3WqKoFT1oILftGjShFO4WIs1dO/jK7SNyz7BMYCYt5PffTxe></script><script src="https://docs.nosqlbench.io/js/email.js?h=ee3dd742e11c5014fdef" defer integrity=sha384-y0LUfjslyVLYZvCOyhELpvKivlXAq27Vnbed54glXoe/pZSYS/Pfqghp/sQt1xcV></script><script src="https://docs.nosqlbench.io/js/codecopy.js?h=0a54f99e682443925d3a" defer integrity=sha384-qssVvPpQgISh4PFkSBGTgXEMzuFO8Hat5m1MsdkpannoByWSTpLfBe4iEVl3+RiP></script><script src="https://docs.nosqlbench.io/js/elasticlunr.min.js?h=4f648b9e42abdef9c436" defer integrity=sha384-Q8viz7rndi8MSNDtItDgVWNSrCumjepopRMlz2nElkWPRXDQAcfiZGJbrCJVXdtw></script><script src="https://docs.nosqlbench.io/search_index.en.js?h=e2df0fd710d0c807a7aa" defer integrity=sha384-nyOftseEtxo2Pc23RFR1hxsCZHtUr0xOCP7JVJ8oGIs+cnDq6GZkzCq2hWZ2cJIh></script><script src="https://docs.nosqlbench.io/js/searchjava.js?h=36b818b07e8b2b318967" defer integrity=sha384-i6K7Uy98ZLnOwn6no8sDUTeBitDmiLHOKxkcJYbjgu6vQ3hdyMQPzmeuX04BRs8J></script><noscript><link href=https://docs.nosqlbench.io/nojs.css rel=stylesheet></noscript><body><header><nav><div><big><a title="NoSQLBench Documentation" href=https://docs.nosqlbench.io></a></big></div><div><div><ul><li><a href=https://docs.nosqlbench.io/tutorials/> Tutorials </a><li><a href=https://docs.nosqlbench.io/guides/> Guides </a><li><a href=https://docs.nosqlbench.io/reference/> Reference </a><li><a href=https://docs.nosqlbench.io/explanations/> Explanations </a><li><a href=https://docs.nosqlbench.io/development/> Development </a><li><a href=https://github.com/nosqlbench/nosqlbench target=_blank> GitHub </a><li><i class="js svgs adjust" id=mode type=reset></i></ul></div><div><div><form autocomplete=off class=js id=searchbox name=goSearch><div class=searchd><input id=searchinput placeholder=Search title=Search><button class="svgs svgm search" title=Search></button></div><div class=results><div id=suggestions></div></div></form></div></div></div></nav></header><main><article><h1><a href=https://docs.nosqlbench.io/guides/workload-design/labeling/labeling-system/>Understanding Labels</a></h1><p>üëâ This provides an intro and overview of the built-in labeling system in NoSQLBench 5.21+.<h2 id=what-are-labels>What are Labels?</h2><p>NoSQLBench allows for your metrics and accompanying annotations to be organized in a self-consistent way with a set of labels and tags. The labeling facility is built-in to NoSQLBench ‚Äì Labeling is not something you add to existing tests results after using it. Labels are innate, self-consistent, and easily leveraged to apply appropriate metadata to your results so that they are well-defined and easily repurposed in other systems.<p>For example, when you name your activity, you are setting a label, even if you didn‚Äôt know it already. You are setting a label of <code>activity=myactivityname</code>. This builds on top of the <em>name everything</em> strategy so that everything from your session down to your op level has a name and accompanying label. This system is implemented efficiently as well, with all labeling mechanisms being applied explicitly during initialization phases, rather than lazily during an activity.<p>Labels are defensive in nature. If you try to define another value for a label which has already been provided for a given runtime scope, an error will be thrown. This ensures that labeling semantics are protected and that users are informed when there would be a labeling conflict. This helps avoid structural or logical errors in their test setup.<p>Labels represent a implied hierarchic structure, and this is how they are assembled. The tree-like structure of components in the runtime allows for labels to be established from the trunk to the branches, with each label attaching to a specific component in the tree. However, when presented for a given component, they are simply a map, including all labels which are <em>inherited</em> from the parent components above. They are retained in the ordered map form where possible for the sake of easy configuration and usage.<h2 id=label-sources>Label Sources</h2><p>Labels are assigned from multiple sources.<h3 id=automatic-labels>Automatic Labels</h3><p>Labels which are part of the runtime scaffolding of NoSQLBench are provided for you, as <em>automatic labels</em>. The examples below show standard labels, and an implied nesting of values. Nesting relationships here imply runtime component relationships and lifecycles. For example, you may expect multiple distinct session labels per node label by default, but session uniqueness is only guaranteed within that node label scope.<p>Examples:<ul><li><code>jobname:nosqlbench</code> The top level name of the metrics bucket for downstream systems. This label is always set, but you can override it as explained below, although generally, it should not be changed. <ul><li><code>instance:default</code> The sub-bucket used for downstream systems. This should be set when you want to isolate your results from others, particularly when doing specialized testing which should not co-mingle results with others. <ul><li><code>node:1.2.3.4</code> The ip address of the first publicly-routable interface. When combined with the session identifier, this tuple is usually sufficient as a proxy for a GUID. If your needs for session identification are finer-grained, then generate a GUID and provide it with <code>--add-labels</code> for each run. <ul><li><code>session:nEXHI88</code> An identifier for each session, basically each time you run NoSQLBench. This identifier is a compact version of the millisecond epoch timestamp. As a user, you can override this value if you need to change from ‚Äúmultiple sessions per node‚Äù, to ‚Äúmultiple nodes per session‚Äù for the purposes of coherent metrics aggregation. <ul><li><code>container:smoketest</code> The name of the container within which any commands are run. Every command in nb runs within a container. For named scenarios, the container name is taken automatically as the step name.<li><code>workload:myworkload</code> <strong>IFF using named scenarios</strong>, the name of your workload template.<li><code>scenario:myscenario</code> <strong>IFF using named scenarios</strong>, the name of the scenario.<li><code>step:rampup</code> <strong>IFF using named scenarios</strong>, the step name. <ul><li><code>activity:rampup</code> The name of your activity, derived by default from the step name for named scenarios, or set directly with the alias activity param. <ul><li>[<code>op:anopname</code>] <strong>ONLY for op-specific metrics, as opposed to activity or session level metrics</strong>. The name of your operation, only provided for metrics which are tied to a specific op template, such as when using the op field <code>instrument:true</code>. <ul><li><code>name:metricname</code> provided directly for each metric which is registered at runtime.</ul></ul></ul></ul></ul></ul></ul></ul><p>Notice that some automatic labels are not always included, such as <code>workload</code>, <code>scenario</code>, and <code>step</code>. This is because these labels are only meaningful in the case that you are using named scenarios. It is strongly recommended that in any downstream views you use and require these labels, and encourage your users to use named scenarios as a rule. Ad-hoc activity construction often leads to inconsistency and ambiguity in testing flows, and named scenarios provide a good template format to avoid this.<p>Metrics, annotations, and logging details can be emitted for any level of labeling, but the labels up to and including <code>session</code> should be considered the minimum set.<h3 id=user-provided-labels>User-Provided Labels</h3><p>Users can inject additional labels in different places:<ul><li>Session labels are added with the <code>--add-labels ...</code> option. Multiple of these can be provided in the form of <code>--add-labels name:value,...</code>.<li>Activity labels are added with the <code>labels</code> activity parameter.<li>Op template labels are added with the core <code>labels</code> op field.<li>Additional labels are added with scripting extensions supporting labels.</ul><h2 id=label-structure>Label Structure</h2><p>For an op-specific metrics, the example label set above would be created at runtime as a simple map (shown as JSON for illustration purposes):<pre class=language-json data-lang=json style=color:#c0c5ce;background-color:#2b303b><code class=language-json data-lang=json><span>{
</span><span>  "</span><span style=color:#a3be8c>jobname</span><span>": "</span><span style=color:#a3be8c>nosqlbench</span><span>",
</span><span>  "</span><span style=color:#a3be8c>instance</span><span>": "</span><span style=color:#a3be8c>default</span><span>",
</span><span>  "</span><span style=color:#a3be8c>node</span><span>": "</span><span style=color:#a3be8c>1.2.3.4</span><span>",
</span><span>  "</span><span style=color:#a3be8c>session</span><span>": "</span><span style=color:#a3be8c>nEXHI88</span><span>",
</span><span>  "</span><span style=color:#a3be8c>container</span><span>": "</span><span style=color:#a3be8c>smoketest</span><span>",
</span><span>  "</span><span style=color:#a3be8c>workload</span><span>": "</span><span style=color:#a3be8c>myworkload</span><span>",
</span><span>  "</span><span style=color:#a3be8c>scenario</span><span>": "</span><span style=color:#a3be8c>myscenario</span><span>",
</span><span>  "</span><span style=color:#a3be8c>step</span><span>": "</span><span style=color:#a3be8c>rampup</span><span>",
</span><span>  "</span><span style=color:#a3be8c>activity</span><span>": "</span><span style=color:#a3be8c>rampup</span><span>",
</span><span>  "</span><span style=color:#a3be8c>op</span><span>": "</span><span style=color:#a3be8c>anopname</span><span>",
</span><span>  "</span><span style=color:#a3be8c>name</span><span>": "</span><span style=color:#a3be8c>metricname</span><span>"
</span><span>}
</span></code></pre><p>It would be rendered (serialized) in whatever form is idiomatic where it is used.<p><strong>Example for metric family name and label set in OpenMetrics:</strong><pre style=color:#c0c5ce;background-color:#2b303b><code><span>metricname{jobname="nosqlbench",node="1.2.3.4",session="nEXHI88",container="smoketest",workload="myworkload",scenario="myscenario",step="rampup",activity="rampup",op="anopname"}
</span></code></pre><p>OR<pre style=color:#c0c5ce;background-color:#2b303b><code><span>{__name__="metricname",jobname="nosqlbench",node="1.2.3.4",session="nEXHI88",container="smoketest",workload="myworkload",scenario="myscenario",step="rampup",activity="rampup",op="anopname"}
</span></code></pre><p><strong>Example labels as tags in a Grafana annotations API call for an activity:</strong><pre class=language-json data-lang=json style=color:#c0c5ce;background-color:#2b303b><code class=language-json data-lang=json><span>{
</span><span>  "</span><span style=color:#a3be8c>dashboardUID</span><span>":"</span><span style=color:#a3be8c>...</span><span>",
</span><span>  "</span><span style=color:#a3be8c>panelId</span><span>":</span><span style=color:#d08770>1</span><span>,
</span><span>  "</span><span style=color:#a3be8c>time</span><span>":</span><span style=color:#d08770>12345</span><span>,
</span><span>  "</span><span style=color:#a3be8c>timeEnd</span><span>":</span><span style=color:#d08770>678910</span><span>,
</span><span>  "</span><span style=color:#a3be8c>tags</span><span>":[
</span><span>    "</span><span style=color:#a3be8c>jobname:nosqlbench</span><span>",
</span><span>    "</span><span style=color:#a3be8c>instance:default</span><span>",
</span><span>    "</span><span style=color:#a3be8c>node:1.2.3.4</span><span>",
</span><span>    "</span><span style=color:#a3be8c>session:nEXHI88</span><span>",
</span><span>    "</span><span style=color:#a3be8c>container:smoketest</span><span>",
</span><span>    "</span><span style=color:#a3be8c>workload:myworkload</span><span>",
</span><span>    "</span><span style=color:#a3be8c>scenario:myscenario</span><span>",
</span><span>    "</span><span style=color:#a3be8c>step:rampup</span><span>",
</span><span>    "</span><span style=color:#a3be8c>activity:rampup</span><span>"
</span><span>  ],
</span><span>  "</span><span style=color:#a3be8c>text</span><span>":"</span><span style=color:#a3be8c>Annotation Description</span><span>"
</span><span>}
</span></code></pre><h2 id=where-are-labels-used>Where are Labels Used?</h2><h3 id=metrics>Metrics</h3><p>All metrics are labeled according to the label set provided. This supports metric systems which use the <a href=https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md rel=noopener target=_blank>OpenMetrics</a> exposition format. The recently added push reporter builds this format out of the labels provided where metrics are instanced.<p>As of 5.21 and newer versions, graphite support is deprecated. This is a necessary change because of the limitations in the graphite metrics naming scheme which directly conflict with modern and more manageable practices for metrics warehousing. Dimensional metrics labels are simply more robust, more expressive, and a more correct way of describing the source of telemetry and logging data.<h3 id=annotations>Annotations</h3><p>Annotations are built-in to NoSQLBench, with the most prominent form being the Grafana-specific annotator. When using grafana with another metrics store like <a href=https://prometheus.io/ rel=noopener target=_blank>Prometheus</a> , or <a href=https://victoriametrics.com/ rel=noopener target=_blank>Victoria Metrics</a> , you can have NoSQLBench send metrics to the metrics collector and concurrently send annotations directly to Grafana. This allows populations of metrics data to have markers for each session, scenario, and activity. These annotations embed execution details, timelines, and labeling data so that the metrics from those lifetimes are directly addressable using the self-same label sets.<p>Grafana annotations have a set of tags which uniquely identify each annotation for lookup. (NOT to be confused with op tags, which allow control of your workload variations.) The labels are provided as values in these tags in conjugate form, such as ‚Äòscenario:myscenario234‚Äô, whereas simple annotation tags would just have a value like ‚Äòscenario‚Äô. This may cause you to pollute your grafana annotation tag space. For now, we are allowing it to work as-is, to see if time-based filtering and recent views are sufficient to limit the user-facing noise and server-side response.<h3 id=logging>Logging</h3><p>Logging events sometimes use the labels to identify errors, unique measurements, or configuration details. Even when the label isn‚Äôt shown as such, there is a direct relationship between a labeled element and it‚Äôs name. For example, a named scenario ‚Äúscenario234‚Äù would be logged as such, and also annotated with an explicit label set that includes ‚Äòscenario=scenario234‚Äô via the annotator system.<h3 id=apis>APIs</h3><p>Labels are inventory addressing systems for runtime scripting. More details on this TBD.<h2 id=why-labeling-standards-matter>Why Labeling Standards Matter</h2><p>In order to make sure that your metrics and annotations have the necessary labels so that the data is traceable, identifiable, and contextual, you may want to set some label validation rules. These rules simply say which label names are required and which are not allowed.<p>Some specific examples for why this is important:<ul><li>You want to look the results of a test which were run 6 months ago, there are 37 other sets of metrics data from the same time frame. Either your data is labeled so you can distinguish the studies, or you‚Äôre just out of luck. You could have simply required a single label with a unique identifier in your standard to avoid this.<li>You want to aggregate results across a set of nodes. Either your data is distinguished by node, or you have bad data. You could simply require a node label to be provided, within the context of your other labels. The validity of your aggregating metrics depends directly on this being stable and distinctly addressable.</ul><p>See <a href=https://docs.nosqlbench.io/guides/workload-design/labeling/labeling-system/labeling-controls.md>Labeling Controls</a> for how to implement label validation and filtering.</article></main><footer><div class=c><nav class=tpad><div></div></nav><p>¬© <span id=year>2025</span> NoSQLBench Documentation<p>Powered by <a href=https://www.getzola.org/ target=_blank>Zola</a> & <a href=https://github.com/jieiku/abridge/ target=_blank>Abridge</a></div></footer><span class=topout> <span class=topleft> </span><a title="Back to Top" class=top href=#><i class="svgs svgh angu"></i></a> </span>